{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.init()\n",
    "device = torch.device(\"cuda:0\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sequence(seq,dictionary):\n",
    "    return torch.tensor([dictionary.get(i,0) for i in seq], dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding='utf8')\n",
    "    model = {}\n",
    "    for line in tqdm_notebook(f):\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# glove_model=loadGloveModel(\"D:/MyCodes/EMBEDDINGS/glove.840B.300d.txt\")\n",
    "\n",
    "# import pickle\n",
    "# with open(\"D:/MyCodes/EMBEDDINGS/glove_840B_300d.pickle\",\"wb\") as fh:\n",
    "#     pickle.dump(glove_model,fh)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"D:/MyCodes/EMBEDDINGS/glove_840B_300d.pickle\",\"rb\") as fh:\n",
    "    embed_dict=pickle.load(fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_labels(data):\n",
    "    \n",
    "    \n",
    "    targets=[]\n",
    "    \n",
    "    for ques in tqdm_notebook(data):\n",
    "        if ques[2].lower() not in targets:\n",
    "            targets.append(ques[2].lower())\n",
    "            \n",
    "    return targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"D:/SEM 7/Core Project/Dataset/Datasets/Classification_task/classification_clusters.pickle\",\"rb\") as fh:\n",
    "    total_data=pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631a56f70a5f4668a8a14eaeac17a0f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uniq_targets=create_labels(total_data)\n",
    "rev_targets=dict((v,k) for k,v in enumerate(uniq_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def return_data(dictionary2,data):\n",
    "    \n",
    "    if dictionary2==None:\n",
    "        print(\"Dictionary is not passed\")\n",
    "        return \n",
    "    \n",
    "    encoded_totl_data=[]\n",
    "    questions=[]\n",
    "    encoded_targets=[]\n",
    "    \n",
    "    for ques in tqdm_notebook(data):\n",
    "        \n",
    "        if \"?\" in ques[0]:\n",
    "            ques[0]=ques[0].replace(\"?\",\" ?\")\n",
    "\n",
    "        \n",
    "        encoded_ques=[word.lower() for word in ques[0].split(\" \")]  # Tokenizing and encoding\n",
    "        encoded_targ=dictionary2[ques[2].lower()] # Encoding targets\n",
    "        \n",
    "        encoded_totl_data.append([encoded_ques,encoded_targ])\n",
    "        questions.append(encoded_ques)\n",
    "        encoded_targets.append(encoded_targ)\n",
    "        \n",
    "        \n",
    "    return encoded_totl_data,questions,encoded_targets\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c23e252be264e12be7f6f52ef937d31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_total_data,questions,encoded_targets= return_data(rev_targets,total_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=list(embed_dict.keys())\n",
    "vocab.insert(0,\"__unk__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "hidden_dim = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pos_lstm_model(nn.Module):\n",
    "    def __init__(self,hidden_dim,embedding_dim,vocab_size,tag_size,batch_size):\n",
    "        super(pos_lstm_model,self).__init__()\n",
    "        \n",
    "#         self.embeddings=nn.Embedding(vocab_size,embedding_dim)\n",
    "        \n",
    "\n",
    "        self.layer1 = nn.LSTM(embedding_dim,hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim,tag_size)\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden = self.init_hidden()\n",
    "#         self.embeddings.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1,batch_size,hidden_dim,device=device),torch.zeros(1,batch_size,hidden_dim,device=device))\n",
    "\n",
    "    def forward(self,sentences):\n",
    "        \n",
    "#         embed = self.embeddings(sentence)\n",
    "#         w2vs=[]\n",
    "    \n",
    "        maxbatch=0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if maxbatch<len(sentence):\n",
    "                maxbatch=len(sentence)\n",
    "        \n",
    "        w2vs=np.zeros((batch_size,maxbatch,embedding_dim),dtype='double')\n",
    "        \n",
    "        \n",
    "        for k,sentence in enumerate(sentences):\n",
    "            \n",
    "            w2v=np.zeros((maxbatch,embedding_dim),dtype='double')\n",
    "            \n",
    "            for q,wdr in enumerate(sentence):\n",
    "                \n",
    "                v = np.zeros(embedding_dim, dtype='float')\n",
    "\n",
    "                try:\n",
    "                    v = embed_dict[wdr]\n",
    "                except:\n",
    "                    pass\n",
    "                w2v[q]=v\n",
    "        \n",
    "            \n",
    "            w2vs[k]=w2v\n",
    "            \n",
    "\n",
    "        w2vs=np.array(w2vs)\n",
    "#         print(\"Embed shape is\",w2vs.shape)\n",
    "#         word_embed = self.word_embeddings(torch.tensor(w2v).cuda())\n",
    "        embed=torch.cuda.FloatTensor(w2vs)\n",
    "        embed=embed.permute(1,0,2)\n",
    "#         print(\"Embed shape is\",embed.shape)\n",
    "        \n",
    "        \n",
    "        output1,self.hidden = self.layer1(embed,self.hidden)\n",
    "#         print(\"Output1 \",output1.shape)\n",
    "#         print(self.hidden[0].shape)\n",
    "        \n",
    "#         print(\"Hidden state is\",self.hidden[0])\n",
    "        \n",
    "        output2=self.layer2(self.hidden[0])\n",
    "\n",
    "        return output2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=700\n",
    "model = pos_lstm_model(hidden_dim,embedding_dim,len(vocab),len(uniq_targets),batch_size)\n",
    "model = model.cuda()\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "# loss_function = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
    "# optimizer = optim.RMSprop(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(questions[0],questions[1],questions[2])\n",
    "# model.zero_grad()\n",
    "# model.hidden = model.init_hidden()\n",
    "# ans=model([questions[0],questions[1],questions[2]])        \n",
    "# print(ans.shape)\n",
    "# print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils import data\n",
    "# trainloader = torch.utils.data.DataLoader(encoded_total_data, batch_size=3,shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data,batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        # this will track the progress of the batches sequentially through the\n",
    "        # data set - once the data reaches the end of the data set it will reset\n",
    "        # back to zero\n",
    "        self.current_idx = 0\n",
    "        # skip_step is the number of words which will be skipped before the next\n",
    "        # batch is skimmed from the data set\n",
    "\n",
    "    def generate(self):\n",
    "\n",
    "#         x = np.zeros((self.batch_size, self.num_steps))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        while True:\n",
    "            x=[]\n",
    "            y=[]\n",
    "\n",
    "            finish_flag=False\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + 1 > len(self.data):\n",
    "                    # reset the index back to the start of the data set\n",
    "                    self.current_idx = 0\n",
    "                    finish_flag=True\n",
    "                    print(\"End of the data\")\n",
    "                \n",
    "                x += [self.data[self.current_idx][0]]\n",
    "                y += [self.data[self.current_idx][1]]\n",
    "                \n",
    "                self.current_idx += 1\n",
    "                \n",
    "    \n",
    "            yield x,y\n",
    "            if finish_flag==True:return\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_generator=BatchGenerator(encoded_total_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps=int(len(encoded_total_data)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e686cf6e01d0428ba99c99e9e1f7d02e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae49c3e8a9ec48aa89dff547ae6f2cce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "no_epochs = 1\n",
    "\n",
    "for i in tqdm_notebook(range(no_epochs),leave=True,desc=\"Epochs\"):\n",
    "#     if i%10 == 0:\n",
    "    \n",
    "    if i>0:\n",
    "        tqdm.write(\"Loss is %f\"%loss)\n",
    "    for sent,tags in tqdm_notebook(data_generator.generate(),position=1,desc='questions',leave=True,total=num_steps):\n",
    "        \n",
    "        \n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        \n",
    "#         tags_in = torch.tensor((), dtype=torch.int32,device=device)\n",
    "#         tags_in.new_full((), tags)\n",
    "        \n",
    "        \n",
    "        tags=torch.tensor(tags,dtype=torch.long,device=device)\n",
    "\n",
    "        pred = model([sent])\n",
    "        \n",
    "#         print(\"Prediction size is\",pred.size())\n",
    "\n",
    "        loss = loss_function(pred,tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"done!\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'model{}_epochs.pt'.format(no_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=0\n",
    "correct=0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sentence, tag in zip(questions,encoded_targets):\n",
    "    #     flatten_parameters()\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        tag_scores= model(sentence) \n",
    "\n",
    "        _, predicted = torch.max(tag_scores.data, 1)\n",
    "        predicted=predicted.cpu().tolist()\n",
    "        print(predicted,tag)\n",
    "        total += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
